{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version : 5.7.28-0ubuntu0.18.04.4 \n",
      "808\n",
      "524\n",
      "['tie ', 'cell phone ', 'wine glass ', 'handbag ', 'person ']\n",
      "525\n",
      "['jisa ', 'peurinteu ', 'daseu maecul ', 'seoulsi sanhagigwan ', 'gongpangeomsa ']\n",
      "526\n",
      "['dogdoyeohaeng ', 'dogdo ', 'gangreung jeongdongjin ', 'jeongdongjin ', 'jejudo ']\n",
      "542\n",
      "['ijaemyeong hangsosim ', 'canseong ', 'jogug gaehyeog ', 'jogug yihog ', 'gongpan ']\n",
      "549\n",
      "['tie ', 'camseog ', 'gugmin ', 'yeosa ', 'person ']\n",
      "550\n",
      "['daehaggyo dongari ', 'hubo ', 'hwajaegibu ', 'cangweon seongdong ', 'jeondangdaehoe ']\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from urllib import parse\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "##db\n",
    "db = pymysql.connect(host='###', user='###', password='###' ,db='###', charset='###')\n",
    "\n",
    "# prepare a cursor object using cursor() method\n",
    "cursor = db.cursor()\n",
    "# execute SQL query using execute() method.\n",
    "cursor.execute(\"SELECT VERSION()\")\n",
    "# Fetch a single row using fetchone() method.\n",
    "data = cursor.fetchone()\n",
    "print(\"Database version : %s \" % data)\n",
    "\n",
    "sql = \"select news_id,image from news\"\n",
    "sql2 = \"select news_id from news\"\n",
    "cursor.execute(\"set names utf8\")#한글 깨질때\n",
    "cursor.execute(sql)#sql문 db에 전달\n",
    "\n",
    "df = pd.read_sql(sql,db)\n",
    "\n",
    "i=0\n",
    "\n",
    "\n",
    "modelFullPath = '###/output_graph.pb' # 읽어들일 graph 파일 경로\n",
    "labelsFullPath = '###t/output_labels.txt'  # 읽어들일 labels 파일 경로\n",
    "\n",
    "def create_graph():\n",
    "    #\"\"\"저장된(saved) GraphDef 파일로부터 graph를 생성하고 saver를 반환한다.\"\"\"\n",
    "    # 저장된(saved) graph_def.pb로부터 graph를 생성한다.\n",
    "    with tf.gfile.FastGFile(modelFullPath, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    \n",
    "def run_inference_on_image():\n",
    "    answer = None\n",
    "\n",
    "    if not tf.gfile.Exists(imagePath):\n",
    "        tf.logging.fatal('File does not exist %s', imagePath)\n",
    "        return answer\n",
    "\n",
    "    image_data = tf.gfile.FastGFile(imagePath, 'rb').read()\n",
    "   \n",
    "\n",
    "    # 저장된(saved) GraphDef 파일로부터 graph를 생성한다.\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                               {'DecodeJpeg/contents:0': image_data})\n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        top_k = predictions.argsort()[-5:][::-1]  # 가장 높은 확률을 가진 5개(top 5)의 예측값(predictions)을 얻는다.\n",
    "        f = open(labelsFullPath, 'r', encoding='euc-kr')\n",
    "       \n",
    "        lines = f.readlines()\n",
    "        #print(len(lines))#카테고리수\n",
    "        labels = [str(w).replace(\"\\n\", \" \") for w in lines]\n",
    "        \n",
    "        data=[]\n",
    "        data_list=[]\n",
    "        for node_id in top_k:\n",
    "            image_name = labels[node_id]\n",
    "            score = predictions[node_id]\n",
    "            data.append(image_name)\n",
    "        data_list.append(data)\n",
    "        \n",
    "        #data=[]#초기화\n",
    "        #print('%s (score = %.5f)' % (image_name, score))\n",
    "        #print(data_list)\n",
    "        #answer = labels[top_k[0]]\n",
    "        \n",
    "        return data_list\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "result = open('###/result2.txt', 'w', encoding='euc-kr',newline='')\n",
    "wtxt = csv.writer(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #추론을 진행할 이미지 경로\n",
    "    #test=[\"https://imgnews.pstatic.net/image/018/2019/09/01/0004459863_001_20190901213806329.jpg?type=w647\",\n",
    "    #     \"https://imgnews.pstatic.net/image/032/2019/09/01/0002960575_001_20190901213913390.jpg?type=w647\"] \n",
    "    \n",
    "    #url = \"https://imgnews.pstatic.net/image/029/2019/09/01/0002550079_001_20190902001525509.jpg?type=w647\"\n",
    "    #response = requests.get(url)\n",
    "    #img = Image.open(BytesIO(response.content))\n",
    "    #imagePath = np.array(img)\n",
    "    #plt.imshow(imagePath)\n",
    "\n",
    "    #print(df.news_id)\n",
    "    #for i in range(1,len(df.values)):\n",
    "\n",
    "    #길이는 같음\n",
    "    id=df.news_id.tolist()\n",
    "    url=df.image.tolist()\n",
    "    result=[]\n",
    "    print(len(id))\n",
    "    for j in range(404,410):\n",
    "        #savePath='###/test/'+str(id[j])+\".jpg\"\n",
    "        imagePath='###/test/'+str(id[j])+\".jpg\"\n",
    "        #urllib.request.urlretrieve(url[j],savePath)\n",
    "        final=run_inference_on_image()\n",
    "        #wtxt.writerow(final[0])\n",
    "        print(id[j])\n",
    "        print(final[0])\n",
    "        \n",
    "        \n",
    "        #if os.path.isfile(savePath):\n",
    "        #    final=run_inference_on_image()\n",
    "        #    print(final)\n",
    "        #    #wtxt.writerow(final)\n",
    "            \n",
    "        #else:\n",
    "        #    urllib.request.urlretrieve(url[j],savePath)\n",
    "        #    final=run_inference_on_image()\n",
    "        #    print(final)\n",
    "        #    #wtxt.writerow(final)\n",
    "       \n",
    "    print(\"완료\")\n",
    "    db.close()     \n",
    "#sql= \"UPDATE `cftable SET user_id='%s' cf_id='%s' rate='%s'\" % (uid,iid,rating)\n",
    "#sql= \"INSERT INTO cftable (user_id,cf_id,rate) VALUES (%s,%s,%s)\"\n",
    "#cursor.execute(sql, (int(uid),int(iid),float(rating)))\n",
    "#db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
